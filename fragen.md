### Offene Fragen 

###### - [ ] Wofür brauche ich den tools-Tag, was wenn er nicht vorhanden ist?


###### - [ ] Wie evaluiere ich meine Ergebnisse/die LLMs?

###### - [ ] Warum Ollama?
- Vor und Nachteile Ollama, vergleichbarer Quellen
###### - [ ] Wie ist die Auswahl an Modellen entstanden?
- Welche Benchmarks?
- Welches Leaderboards?
- Welche anderen Quelle?
- Nach gegebenen Kriterien 
    - lokal 
    - RAM nutzung <16GB

###### - [ ] Wie übergebe ich Repositories am besten dem LLM?
- [yek](https://github.com/bodo-run/yek)
- [code2prompt](https://github.com/mufeedvh/code2prompt)
- [aider](https://aider.chat/)

###### - [ ] Was ist der Unterschied zwischen base und Instructed

###### - [ ] Warum macht es sinn verschiedene Modelle für verschiedene aufgaben zu nutzen?

###### - [ ] Gibt es Methoden zu Promptengineering/Output evaluation usw?

###### - [ ] Wie kann ich mit Finetuning meine Agenten verbessern?
- durch FT können konventionen zu Coden gelernt werden oder zur Bennennung von z.B. Commits die in dem Unternehmen anders gemacht werden als es das Modell kennt
- man kann den kleinen modellen spezifische informationen geben die sie für die jewweilige aufgabe benötigen

###### - [ ] Wie konfiguriere ich eine Modelfile und wie verbessert sie meine Ausgabe?

